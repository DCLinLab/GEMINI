{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from aicsimageio import AICSImage\n",
    "from cellpose import models\n",
    "import pyclesperanto_prototype as cle\n",
    "import numpy as np\n",
    "from skimage.filters import threshold_otsu, gaussian\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.morphology import disk, erosion, remove_small_objects\n",
    "from skimage.measure import label\n",
    "from scipy.ndimage import distance_transform_edt, find_objects\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import label2rgb\n",
    "from scipy.ndimage import find_objects  # corrected import for find_objects\n",
    "from regionpropsExtension import RegionPropertiesExtension, TEXTURE_FEATURE_NAMES\n",
    "from numpy import linalg as LA\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.stats import median_abs_deviation\n",
    "from skimage.measure import _moments, find_contours\n",
    "from skimage.measure._regionprops import RegionProperties, _cached, only2d\n",
    "from skimage.feature import graycomatrix\n",
    "from skimage.segmentation import find_boundaries\n",
    "from pyefd import elliptic_fourier_descriptors\n",
    "from functools import cached_property\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "TEXTURE_PERCENTILES = (25, 50, 75)\n",
    "TEXTURE_CATEGORIES = [\"Contrast\", \"Dissimilarity\", \"Homogeneity\", \"Energy\", \"Correlation\"]\n",
    "TEXTURE_SUMM_STATISTICS = [f\"{it}%\" for it in TEXTURE_PERCENTILES] + [\"mean\", \"std\", \"mad\"]\n",
    "TEXTURE_FEATURE_NAMES = [f\"{it0}_{it1}\" for it0 in TEXTURE_CATEGORIES for it1 in TEXTURE_SUMM_STATISTICS]\n",
    "\n",
    "\n",
    "def safe_log_10_v0(value):\n",
    "    \"\"\"https://stackoverflow.com/questions/21610198/runtimewarning-divide-by-zero-encountered-in-log\"\"\"\n",
    "    value = np.abs(value)\n",
    "    result = np.where(value > 1e-12, value, -12)\n",
    "    # print(result)\n",
    "    res = np.log10(result, out=result, where=result > 1e-12)\n",
    "    return res\n",
    "\n",
    "\n",
    "def safe_log_10_v1(value):\n",
    "    \"\"\"Pankaj\"\"\"\n",
    "    return -np.log(1+np.abs(value))\n",
    "\n",
    "\n",
    "def regionprops(w0_mask, w1_mask, w2_mask, w4_mask, img, n_levels):\n",
    "    N = len(np.unique(w0_mask)) - 1\n",
    "    regions = np.zeros((5, N), dtype=object)\n",
    "    has_nucleoli = np.zeros((N, 1), dtype=np.uint8)\n",
    "\n",
    "    max_ = np.amax(w0_mask)\n",
    "    w0_objects = ndi.find_objects(w0_mask, max_label=max_)\n",
    "    w1_objects = ndi.find_objects(w1_mask, max_label=max_)\n",
    "    w2_objects = ndi.find_objects(w2_mask, max_label=max_)\n",
    "    w4_objects = ndi.find_objects(w4_mask, max_label=max_)\n",
    "    cnt = 0\n",
    "    for ii in range(max_):\n",
    "        if w0_objects[ii] is None:\n",
    "            continue\n",
    "        label = ii + 1\n",
    "        w0_props = RegionPropertiesExtension(w0_objects[ii], label, w0_mask, img[0])\n",
    "        w1_props = RegionPropertiesExtension(w1_objects[ii], label, w1_mask, img[1])\n",
    "        w3_props = RegionPropertiesExtension(w1_objects[ii], label, w1_mask, img[3])\n",
    "        w4_props = RegionPropertiesExtension(w4_objects[ii], label, w4_mask, img[4])\n",
    "        if w2_objects[ii] is not None:\n",
    "            w2_props = RegionPropertiesExtension(w2_objects[ii], label, w2_mask, img[2],n_levels)\n",
    "            has_nucleoli[cnt] = 1\n",
    "        else:\n",
    "            w2_props = None\n",
    "            has_nucleoli[cnt] = 0\n",
    "\n",
    "        regions[0, cnt] = w0_props\n",
    "        regions[1, cnt] = w1_props\n",
    "        regions[2, cnt] = w2_props\n",
    "        regions[3, cnt] = w3_props\n",
    "        regions[4, cnt] = w4_props\n",
    "\n",
    "        cnt += 1\n",
    "\n",
    "    return regions, has_nucleoli\n",
    "\n",
    "\n",
    "class RegionPropertiesExtension(RegionProperties):\n",
    "    \"\"\"Please refer to `skimage.measure.regionprops` for more information\n",
    "    on the available region properties.\n",
    "    \"\"\"\n",
    "    ndim = 2\n",
    "    bd_val = 10\n",
    "    bd_padding = [(bd_val, bd_val), (bd_val, bd_val)]\n",
    "\n",
    "    n_levels = 8\n",
    "    n_pos_pixels_lb = 10\n",
    "    corr_tolerance = 1e-8\n",
    "    distances = np.arange(1, 21)\n",
    "    angles = np.array([0, np.pi/2])\n",
    "    angles_str = [0, \"pi/2\"]\n",
    "    intensity_percentiles = (10, 25, 75, 90)\n",
    "\n",
    "    def __init__(self, slice, label, label_image, intensity_image, channel_name,\n",
    "                 cache_active=True, ):\n",
    "        super().__init__(slice, label, label_image, intensity_image, cache_active)\n",
    "\n",
    "        \n",
    "        self.channel_name = channel_name\n",
    "        self.I, self.J = self.haralick_ij()\n",
    "        self.corr_I, self.corr_J = self.haralick_corr_ij()\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    @_cached\n",
    "    def einsum_instruct_2(self):\n",
    "        return \"ijkm,ijkm->km\"\n",
    "\n",
    "    @property\n",
    "    @_cached\n",
    "    def einsum_instruct_3(self):\n",
    "        return \"ijkm,ijkm,ijkm->km\"\n",
    "\n",
    "    @_cached\n",
    "    def haralick_ij(self):\n",
    "        # create weights for specified property\n",
    "        I, J = np.ogrid[0:self.n_levels, 0:self.n_levels]\n",
    "        return I, J\n",
    "\n",
    "    @_cached\n",
    "    def haralick_corr_ij(self):\n",
    "        I = np.array(range(0, self.n_levels)).reshape((self.n_levels, 1, 1, 1))\n",
    "        J = np.array(range(0, self.n_levels)).reshape((1, self.n_levels, 1, 1))\n",
    "        return I, J\n",
    "\n",
    "    @property\n",
    "    @_cached\n",
    "    def weights0(self):\n",
    "        weights0 = (self.I - self.J) ** 2\n",
    "        weights0 = weights0.reshape((self.n_levels, self.n_levels, 1, 1))\n",
    "        return weights0\n",
    "\n",
    "\n",
    "    @property\n",
    "    @_cached\n",
    "    def weights1(self):\n",
    "        weights1 = np.abs(self.I - self.J)\n",
    "        weights1 = weights1.reshape((self.n_levels, self.n_levels, 1, 1))\n",
    "        return weights1\n",
    "\n",
    "    @property\n",
    "    @_cached\n",
    "    def weights2(self):\n",
    "        return 1. / (1. + self.weights0)\n",
    "\n",
    "    @property\n",
    "    @_cached\n",
    "    def bins(self):\n",
    "        return np.linspace(self.intensity_min, self.intensity_max, self.n_levels)\n",
    "\n",
    "\n",
    "    @property\n",
    "    @_cached\n",
    "    def image_intensity_discrete(self):\n",
    "        return np.int32(np.digitize(self.image_intensity, self.bins, right=True))\n",
    "\n",
    "    @property\n",
    "    @_cached\n",
    "    def image_int32(self):\n",
    "        return np.int32(self.image)\n",
    "\n",
    "    @property\n",
    "    @only2d\n",
    "    @_cached\n",
    "    def moments_hu(self):\n",
    "        mh = _moments.moments_hu(self.moments_normalized)\n",
    "        return -1 * np.sign(mh) * safe_log_10_v0(mh)\n",
    "\n",
    "    @property\n",
    "    @only2d\n",
    "    @_cached\n",
    "    def moments_weighted_hu(self):\n",
    "        \n",
    "        mhw = _moments.moments_hu(self.moments_weighted_normalized)\n",
    "        return -1 * np.sign(mhw) * safe_log_10_v0(mhw)\n",
    "\n",
    "    @property\n",
    "    @_cached\n",
    "    def moments_weighted_normalized(self):\n",
    "        \n",
    "        mwn = _moments.moments_normalized(self.moments_weighted_central, order=3)\n",
    "       \n",
    "        return -1 * np.sign(mwn) * safe_log_10_v0(mwn)\n",
    "\n",
    "    @property\n",
    "    @_cached\n",
    "    def image_intensity_vec(self):\n",
    "        return self.image_intensity[self.image_intensity > 0]\n",
    "\n",
    "    @property\n",
    "    @_cached\n",
    "    def intensity_statistics(self, ):\n",
    "        if len(self.image_intensity_vec) < self.n_pos_pixels_lb:\n",
    "            \n",
    "            return (0, )*(len(self.intensity_percentiles)+4)\n",
    "        percentiles = np.nanpercentile(self.image_intensity_vec, self.intensity_percentiles)\n",
    "        intensity_median, intensity_mad, intensity_mean, intensity_std = \\\n",
    "            np.nanmedian(self.image_intensity_vec), median_abs_deviation(self.image_intensity_vec), \\\n",
    "            np.nanmean(self.image_intensity_vec), np.nanstd(self.image_intensity_vec)\n",
    "        return tuple(percentiles) + (intensity_median, intensity_mad, intensity_mean, intensity_std,)\n",
    "\n",
    "    @cached_property\n",
    "    def voxel_coordinates(self):\n",
    "        \n",
    "        return np.array(np.where(self.image))\n",
    "    @property\n",
    "    @_cached\n",
    "    def glcm(self, ):  \n",
    "        \n",
    "        P = graycomatrix(\n",
    "            self.image_intensity_discrete,\n",
    "            distances=self.distances,\n",
    "            angles=self.angles,\n",
    "            levels=self.n_levels,\n",
    "            symmetric=False, normed=False)\n",
    "\n",
    "       \n",
    "        P = P.astype(np.float32)\n",
    "        glcm_sums = np.sum(P, axis=(0, 1), keepdims=True)\n",
    "        glcm_sums[glcm_sums == 0] = 1\n",
    "        P /= glcm_sums\n",
    "        return P\n",
    "\n",
    "    @cached_property\n",
    "    def glcm_features(self,):\n",
    "       \n",
    "       \n",
    "        (num_level, num_level2, num_dist, num_angle) = self.glcm.shape\n",
    "\n",
    "\n",
    "        contrast = np.sum(self.glcm * self.weights0, axis=(0, 1))\n",
    "        dissimilarity = np.sum(self.glcm * self.weights1, axis=(0, 1))\n",
    "        homogeneity = np.sum(self.glcm * self.weights2, axis=(0, 1))\n",
    "     \n",
    "        energy = LA.norm(self.glcm, ord='fro', axis=(0, 1))\n",
    "   \n",
    "        correlation = np.zeros((num_dist, num_angle), dtype=np.float32)\n",
    "        diff_i = self.corr_I - np.sum(self.corr_I * self.glcm, axis=(0, 1))\n",
    "        diff_j = self.corr_J - np.sum(self.corr_J * self.glcm, axis=(0, 1))\n",
    "        std_i = np.sqrt(np.sum(self.glcm * (diff_i ** 2), axis=(0, 1)))\n",
    "        std_j = np.sqrt(np.sum(self.glcm * (diff_j ** 2), axis=(0, 1)))\n",
    "        cov = np.sum(self.glcm * (diff_i * diff_j), axis=(0, 1))\n",
    "\n",
    "     \n",
    "        mask_0 = std_i < self.corr_tolerance\n",
    "        mask_0[std_j < self.corr_tolerance] = True\n",
    "        correlation[mask_0] = 1\n",
    "     \n",
    "        mask_1 = ~mask_0\n",
    "        correlation[mask_1] = cov[mask_1] / (std_i[mask_1] * std_j[mask_1])\n",
    "        \n",
    "        contrast = tuple(np.percentile(contrast, q=TEXTURE_PERCENTILES)) + \\\n",
    "                   (np.mean(contrast), np.std(contrast), median_abs_deviation(contrast, axis=None), )\n",
    "        dissimilarity = tuple(np.percentile(dissimilarity, q=TEXTURE_PERCENTILES)) + \\\n",
    "                        (np.mean(dissimilarity), np.std(dissimilarity), median_abs_deviation(dissimilarity, axis=None),)\n",
    "        homogeneity = tuple(np.percentile(homogeneity, q=TEXTURE_PERCENTILES)) + \\\n",
    "                      (np.mean(homogeneity), np.std(homogeneity), median_abs_deviation(homogeneity, axis=None),)\n",
    "        energy = tuple(np.percentile(energy, q=TEXTURE_PERCENTILES)) + \\\n",
    "                 (np.mean(energy), np.std(energy), median_abs_deviation(energy, axis=None),)\n",
    "        correlation = tuple(np.percentile(correlation, q=TEXTURE_PERCENTILES)) + \\\n",
    "                      (np.mean(correlation), np.std(correlation), median_abs_deviation(correlation, axis=None),)\n",
    "        return contrast+dissimilarity+homogeneity+energy+correlation\n",
    "\n",
    "    @property\n",
    "    @_cached\n",
    "    def efc_ratio(self, ):\n",
    "        bd = find_boundaries(np.pad(self.image, self.bd_padding, 'constant', constant_values=(0, 0)))\n",
    "        bd_contours = find_contours(bd, .1)[0]\n",
    "        efc = elliptic_fourier_descriptors(bd_contours,\n",
    "                                           normalize=True,\n",
    "                                           order=15)\n",
    "\n",
    "        efcs = np.sqrt(efc[:, 0] ** 2 + efc[:, 1] ** 2) + np.sqrt(efc[:, 2] ** 2 + efc[:, 3] ** 2)\n",
    "        ratio = efcs[0] / np.sum(efcs[1:])\n",
    "        return ratio\n",
    "\n",
    "    @property\n",
    "    @_cached\n",
    "    def circularity(self, ):\n",
    "        if self.perimeter > 1e-6:\n",
    "            return (4 * np.pi * self.area) / self.perimeter ** 2\n",
    "        else:\n",
    "            return np.nan\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_czi_maxproject(czi_path):\n",
    "    img = AICSImage(czi_path)\n",
    "    data4d = img.get_image_data(\"CZYX\", S=0, T=0)  \n",
    "    return data4d.max(axis=1)                     \n",
    "\n",
    "def segment_cells_with_watershed(nuc, cyto, thr=None):\n",
    "    if thr is None:\n",
    "        thr = threshold_otsu(cyto)\n",
    "    mask = cyto > thr\n",
    "    dist = distance_transform_edt(mask)\n",
    "    return watershed(-dist, nuc, mask=mask).astype(np.uint16)\n",
    "\n",
    "def segment_stage1(img_w1, img_w2,\n",
    "                   alg_w1, alg_w2,\n",
    "                   p1, p2):\n",
    "    cp = models.CellposeModel(gpu=True)\n",
    "\n",
    "    def run_cp(img,p):\n",
    "        masks, *_ = cp.eval([img],\n",
    "            diameter            = p.get(\"diameter\", None),\n",
    "            channels            = p.get(\"channels\", [0,0]),\n",
    "            flow_threshold      = p.get(\"flow_threshold\", 0.4),\n",
    "            cellprob_threshold  = p.get(\"cellprob_threshold\", 0.0),\n",
    "            normalize           = {\"tile_norm_blocksize\": p.get(\"tile_norm_blocksize\",0)},\n",
    "            niter               = p.get(\"niter\", None),\n",
    "        )\n",
    "        return masks[0].astype(np.uint16)\n",
    "\n",
    "    def run_pycle(img,p):\n",
    "        g = cle.push(img.astype(np.float32))\n",
    "        return cle.voronoi_otsu_labeling(\n",
    "            g,\n",
    "            spot_sigma    = p.get(\"spot_sigma\",10),\n",
    "            outline_sigma = p.get(\"outline_sigma\",1)\n",
    "        ).astype(np.uint16)\n",
    "\n",
    "\n",
    "    if   alg_w1==\"cellpose\": w1 = run_cp(img_w1,p1)\n",
    "    elif alg_w1==\"pycle\":    w1 = run_pycle(img_w1,p1)\n",
    "    else: raise ValueError(alg_w1)\n",
    "\n",
    "\n",
    "    if   alg_w2==\"cellpose\":  w2 = run_cp(img_w2,p2)\n",
    "    elif alg_w2==\"pycle\":     w2 = run_pycle(img_w2,p2)\n",
    "    elif alg_w2==\"watershed\": w2 = segment_cells_with_watershed(w1,img_w2,\n",
    "                                           thr=p2.get(\"mask_threshold\",None))\n",
    "    else: raise ValueError(alg_w2)\n",
    "\n",
    "\n",
    "    w_cell = w2.copy()\n",
    "    w_cell[w1>0] = w1[w1>0]\n",
    "\n",
    "    return w1, w2, w_cell\n",
    "\n",
    "\n",
    "\n",
    "def segment_stage2(w1, w_cell, data2d, channel_names,\n",
    "                   nucleoli_channel=\"RNA\",\n",
    "                   mito_channel=\"MITO\",\n",
    "                   min_nuc_size=10,\n",
    "                   min_mito_size=20,\n",
    "                   erode_radius=2):\n",
    "   \n",
    "    w1e = erosion(w1, disk(erode_radius))\n",
    "\n",
    "    idx_n = channel_names.index(nucleoli_channel)\n",
    "    idx_m = channel_names.index(mito_channel)\n",
    "    img_n = data2d[idx_n]\n",
    "    img_m = data2d[idx_m]\n",
    "\n",
    "    \n",
    "    w3 = np.zeros_like(w1, dtype=np.uint16)\n",
    "    for lid, slc in enumerate(find_objects(w1e), start=1):\n",
    "        if slc is None: continue\n",
    "        seed = (w1e[slc]==lid)\n",
    "        if not seed.any(): continue\n",
    "        sub = img_n[slc]*seed\n",
    "        blur = gaussian(sub, sigma=1)\n",
    "        thr  = threshold_otsu(blur[seed])\n",
    "        bin_ = blur>thr\n",
    "        lab  = label(bin_)\n",
    "        lab  = remove_small_objects(lab, min_nuc_size)\n",
    "        w3[slc][lab>0] = lid\n",
    "\n",
    "   \n",
    "    w5 = np.zeros_like(w_cell, dtype=np.uint16)\n",
    "    for lid, slc in enumerate(find_objects(w_cell), start=1):\n",
    "        if slc is None: continue\n",
    "        seed = (w_cell[slc]==lid)\n",
    "        if not seed.any(): continue\n",
    "        sub = img_m[slc]*seed\n",
    "        thr = threshold_otsu(sub[seed])\n",
    "        bin_= sub>thr\n",
    "        lab = label(bin_)\n",
    "        lab = remove_small_objects(lab, min_mito_size)\n",
    "        w5[slc][lab>0] = lid\n",
    "\n",
    "    return w3, w5\n",
    "\n",
    "\n",
    "from scipy.ndimage import find_objects\n",
    "\n",
    "def extract_features_with_rp(data2d, channels, masks):\n",
    "    \n",
    "    max_label = int(masks['cell'].max())\n",
    "    slices = {}\n",
    "    for key, mask_img in masks.items():\n",
    "        s = find_objects(mask_img)\n",
    "        if len(s) < max_label:\n",
    "            s = list(s) + [None] * (max_label - len(s))\n",
    "        slices[key] = s\n",
    "\n",
    "    rows = []\n",
    "    for lab in range(1, max_label+1):\n",
    "        if slices['cell'][lab-1] is None:\n",
    "            continue\n",
    "        feat = {'label': lab}\n",
    "        comp_info = {\n",
    "            'nucleus':  ('DAPI',   masks['nucleus'],  slices['nucleus']),\n",
    "            'cyto':     ('ER',     masks['cyto'],     slices['cyto']),\n",
    "            'nucleoli': ('RNA',    masks['nucleoli'], slices['nucleoli']),\n",
    "            'mito':     ('MITO',   masks['mito'],     slices['mito']),\n",
    "            'cell':     ('DAPI',   masks['cell'],     slices['cell']),\n",
    "        }\n",
    "        for comp, (ch_name, mask_img, obj_slices) in comp_info.items():\n",
    "            slc = obj_slices[lab-1]\n",
    "            if slc is None: \n",
    "                continue\n",
    "            intensity_img = data2d[channels.index(ch_name)]\n",
    "            rp = RegionPropertiesExtension(\n",
    "                slice=slc,\n",
    "                label=lab,\n",
    "                label_image=mask_img,\n",
    "                intensity_image=intensity_img,\n",
    "                channel_name=comp\n",
    "            )\n",
    "          \n",
    "            feat[f\"{comp}_area\"]         = rp.area\n",
    "            feat[f\"{comp}_eccentricity\"] = rp.eccentricity\n",
    "            feat[f\"{comp}_solidity\"]     = rp.solidity\n",
    "            feat[f\"{comp}_extent\"]       = rp.extent\n",
    "            stats = rp.intensity_statistics\n",
    "            stat_names = list(rp.intensity_percentiles) + ['median','mad','mean','std']\n",
    "            for name, val in zip(stat_names, stats):\n",
    "                feat[f\"{comp}_int_{name}\"] = val\n",
    "            tex_vals = rp.glcm_features\n",
    "            for tex_name, tex_val in zip(TEXTURE_FEATURE_NAMES, tex_vals):\n",
    "                feat[f\"{comp}_tex_{tex_name}\"] = tex_val\n",
    "\n",
    "        rows.append(feat)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def plot_stage2_qc(\n",
    "    data2d, \n",
    "    channel_names, \n",
    "    w1, w2, w3, w_cell, w5, \n",
    "    alpha=0.6, \n",
    "    figsize=(20, 8)\n",
    "):\n",
    "    \"\"\"\n",
    "    Display a 2×5 grid: top row raw channels, bottom row segmentation masks.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 5, figsize=figsize)\n",
    "\n",
    "    # Top row: raw channels\n",
    "    for i, ch in enumerate(channel_names):\n",
    "        ax = axes[0, i]\n",
    "        ax.imshow(data2d[i], cmap='gray')\n",
    "        ax.set_title(ch)\n",
    "        ax.axis('off')\n",
    "\n",
    "    # Bottom row: masks\n",
    "    masks      = [w1, w2, w3, w_cell, w5]\n",
    "    mask_titles= [\"Nuclei\", \"Cytosol\", \"Nucleoli\", \"Cell\", \"Mito\"]\n",
    "\n",
    "    for i, (msk, title) in enumerate(zip(masks, mask_titles)):\n",
    "        ax = axes[1, i]\n",
    "        ax.imshow(label2rgb(msk, bg_label=0, alpha=alpha))\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def batch_process_czi_folder_split(\n",
    "    folder_path: str,\n",
    "    output_folder:str,\n",
    "    channel_names: list,\n",
    "    p1: dict,\n",
    "    p2: dict,\n",
    "    min_nuc_size: int,\n",
    "    min_mito_size: int,\n",
    "    erode_radius: int\n",
    "):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for filepath in sorted(glob.glob(os.path.join(folder_path, \"*.czi\"))):\n",
    "        fname = os.path.splitext(os.path.basename(filepath))[0]\n",
    "        # Stage I & II\n",
    "        data2d = load_czi_maxproject(filepath)\n",
    "        img_w1 = data2d[channel_names.index(\"DAPI\")]\n",
    "        img_w2 = data2d[channel_names.index(\"ER\")]\n",
    "        w1, w2, w_cell = segment_stage1(img_w1, img_w2, \"cellpose\", \"watershed\", p1, p2)\n",
    "        w3, w5 = segment_stage2(w1, w2, data2d, channel_names,\n",
    "                                nucleoli_channel=\"RNA\",\n",
    "                                mito_channel=\"MITO\",\n",
    "                                min_nuc_size=min_nuc_size,\n",
    "                                min_mito_size=min_mito_size,\n",
    "                                erode_radius=erode_radius)\n",
    "\n",
    "        # feature extraction\n",
    "        masks = {'nucleus':w1,'cyto':w2,'nucleoli':w3,'cell':w_cell,'mito':w5}\n",
    "        plot_stage2_qc(data2d, channel_names, w1, w2, w3, w_cell, w5)\n",
    "        df = extract_features_with_rp(data2d, channel_names, masks)\n",
    "\n",
    "        # add filename\n",
    "        df['filename'] = fname\n",
    "\n",
    "        # save per‐file\n",
    "        out_csv = os.path.join(output_folder, f\"{fname}_features.csv\")\n",
    "        df.to_csv(out_csv, index=False)\n",
    "        print(f\"✔ {fname}: {len(df)} cells → '{out_csv}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_process_czi_folder_split(\n",
    "    folder_path   = r\"folder of multicolor czi file\",\n",
    "    output_folder = r\"folder to store the feature extract from each image\",\n",
    "    channel_names = [\"DAPI\",\"ER\",\"RNA\",\"AG\",\"MITO\"],\n",
    "    p1            = {\"diameter\":15},\n",
    "    p2            = {\"mask_threshold\":None},\n",
    "    min_nuc_size  = 5,\n",
    "    min_mito_size = 20,\n",
    "    erode_radius  = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_folder = r\"folder to store the feature extract from each image\"\n",
    "output_csv   = r\"combined multi-well (replicates) to one csv file\"\n",
    "\n",
    "\n",
    "csv_paths = sorted(glob.glob(os.path.join(input_folder, \"*_features.csv\")))\n",
    "\n",
    "\n",
    "dfs = []\n",
    "for fp in csv_paths:\n",
    "    df = pd.read_csv(fp)\n",
    "    dfs.append(df)\n",
    "\n",
    "all_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "all_df.to_csv(output_csv, index=False)\n",
    "print(f\"Merged {len(dfs)} files → {all_df.shape[0]} cells saved to:\\n  {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def significance_stars(p):\n",
    "    if p < 0.001: return '***'\n",
    "    elif p < 0.01: return '**'\n",
    "    elif p < 0.05: return '*'\n",
    "    else: return 'ns'\n",
    "\n",
    "\n",
    "def add_stat_annotation(ax, x1, x2, y, h, text):\n",
    "    ax.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c='k')\n",
    "    ax.text((x1+x2)/2, y+h, text, ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "\n",
    "group_order = ['0 h', '12 h', '24 h', '48 h']\n",
    "comparisons = [('0 h','12 h'), ('0 h','24 h'), ('0 h','48 h')]\n",
    "agg = pd.read_csv('featruesofinterest.csv')\n",
    "\n",
    "agg['Group'] = pd.Categorical(agg['Group'], categories=group_order, ordered=True)\n",
    "\n",
    "agg_features = [\"median_nucleus_area\", \"median_cyto_area\", \n",
    "                \"median_mito_area\", \"median_nucleoli_area\"]\n",
    "cells = agg[\"Cell\"].unique()\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=len(cells), \n",
    "    ncols=len(agg_features),\n",
    "    figsize=(len(agg_features)*4, len(cells)*4),\n",
    "    sharex='col'\n",
    ")\n",
    "\n",
    "for i, cell in enumerate(cells):\n",
    "    sub = agg[agg[\"Cell\"] == cell]\n",
    "    \n",
    "    for j, feat in enumerate(agg_features):\n",
    "        ax = axes[i, j]\n",
    "\n",
    "        sns.barplot(\n",
    "            x=\"Group\", y=feat, data=sub,\n",
    "            errorbar=\"sd\", edgecolor=\"k\", fill=False, color=\"black\",ax=ax\n",
    "        )\n",
    "        sns.stripplot(\n",
    "            x=\"Group\", y=feat, data=sub,\n",
    "            color=\"black\", alpha=0.6, size=4,\n",
    "            jitter=True, ax=ax\n",
    "        )\n",
    "        \n",
    " \n",
    "        y_min, y_max = ax.get_ylim()\n",
    "        h = (y_max - y_min) * 0.05\n",
    "        for k, (g1, g2) in enumerate(comparisons):\n",
    "            d1 = sub.loc[sub['Group'] == g1, feat]\n",
    "            d2 = sub.loc[sub['Group'] == g2, feat]\n",
    "            stat, p = ttest_ind(d1, d2, equal_var=False)\n",
    "            stars = significance_stars(p)\n",
    "            x1 = group_order.index(g1)\n",
    "            x2 = group_order.index(g2)\n",
    "            y = y_max + k * h * 2\n",
    "            add_stat_annotation(ax, x1, x2, y, h, stars)\n",
    "        \n",
    "\n",
    "        if i == 0:\n",
    "            ax.set_title(feat.replace(\"_\", \" \").title(), pad=10)\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(f\"{cell}\\n\", fontsize=12)\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "        if i == len(cells) - 1:\n",
    "            ax.set_xlabel(\"Group\")\n",
    "        else:\n",
    "            ax.set_xlabel(\"\")\n",
    "\n",
    "        ax.tick_params(axis='x', rotation=45, direction='in')\n",
    "        ax.tick_params(axis='y', direction='in')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
